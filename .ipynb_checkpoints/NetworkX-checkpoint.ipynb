{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "honey-marina",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-company",
   "metadata": {},
   "source": [
    "In this tutorial, we will attempt to visualize and get insights on Pittsburgh's HealthyRide bicycle network data. This data was fetched from https://healthyridepgh.com/media-kit/ and https://healthyridepgh.com/data/. For analysizing this data, we will be exploring a few libraries that help deal with network data, mapping, and data analysis. By visualizing this data, we hope to understand common ride patterns, hotspots for biking, how they relate to other biking infrastructure (bike lanes etc.), as well as other insights into trips."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-graduate",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "To injest and clean our data, we will be using Pandas. We will also be using it to analyze the data and perform operations such as aggregations. Pandas offers functionality to process the data, clean it, and make it usable for network analysis and other libraries. More information about Pandas can be found here: https://pandas.pydata.org/\n",
    "\n",
    "The data that we are looking at primarily involves trip information (origin, destination, time etc.). Therefore, we can best process this data in the form of a graph, and then use that graph to conduct further analysis. Python offers various graph libraries, but the most popular one with extensive documentation is networkx. More info can be found here: https://networkx.org/. It offers extensive functionality to create networks from data (including pandas dataframes) and understand properties of these networks.\n",
    "\n",
    "Finally, to visualize our data geographically, we will be using Google Maps. Google Maps has extensive inbuilt infrastructure and capabilties to represent geographical data. To use Google Maps in the Jupyter notebook, we can look to the conda gmaps library. This library has built on Google Maps API functionality to view Google Maps in a Jupyter Notebook environment. More information about this library can be found here: https://jupyter-gmaps.readthedocs.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-crown",
   "metadata": {},
   "source": [
    "### Installing the libraries\n",
    "To install these libraries, you must first run some commands in your local miniconda environment.\n",
    "For pandas, run \n",
    "```\n",
    "conda install pandas\n",
    "```\n",
    "For networkx, run\n",
    "```\n",
    "conda install networkx\n",
    "```\n",
    "For gmaps, first terminate your existing notebook process. Then, in a new conda environment, run the following commands:\n",
    "```\n",
    "conda install -c conda-forge gmaps\n",
    "jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "jupyter nbextension enable --py --sys-prefix gmaps\n",
    "```\n",
    "After you run these commands, restart your notebook and you should be able to view the maps. Run these commands below to import the libraries and start consuming them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "further-borough",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gmaps\n",
    "import gmaps.datasets\n",
    "\n",
    "gmaps.configure(api_key='AIzaSyDfD5CNUra6NLeO4HBnYsaDvsHvW7ssLF8') # Fill in with your API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-beach",
   "metadata": {},
   "source": [
    "### Fetching the trip and local stations data\n",
    "To get started, navigate to https://healthyridepgh.com/data/ and download the 2020 Q1 data zip file. Unzip this file, and move the 2 csv files into the project directory. The names of the 2 files should be 'healthy-ride-rentals-2021-q1.csv' and 'healthy-ride-station-locations-2021-q1.csv'  \n",
    "  \n",
    "We will now use the inbuilt pandas csv reader to get this data, and typecast object to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "incredible-above",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Trip id           Starttime            Stoptime  Tripduration  \\\n",
      "0  111375309 2021-01-12 12:48:00 2021-01-12 13:04:00           963   \n",
      "1  111390480 2021-01-13 09:32:00 2021-01-13 09:39:00           387   \n",
      "\n",
      "  From station id            From station name To station id  \\\n",
      "0           49641           11th St & Penn Ave          1061   \n",
      "1           49391  E Liberty Blvd & Negley Ave          1064   \n",
      "\n",
      "                   To station name  \n",
      "0              33rd St & Penn Ave   \n",
      "1  Frankstown Ave & E Liberty Blvd  \n"
     ]
    }
   ],
   "source": [
    "# Reading the trip data\n",
    "df_trips = pd.read_csv('healthy-ride-rentals-2021-q1.csv', dtype=\"str\", keep_default_na=False)\n",
    "# Dropping columns that are not as useful\n",
    "df_trips = df_trips.drop(['Bikeid', 'Usertype'], axis=1)\n",
    "# Dropping rows with empty origin and/or dest info\n",
    "df_trips = df_trips.drop(df_trips[df_trips['To station id'] == ''].index)\n",
    "df_trips = df_trips.drop(df_trips[df_trips['From station id'] == ''].index)\n",
    "# Convert the tripduration and dates to the relevant datatypes\n",
    "df_trips = df_trips.astype({'Tripduration': 'int32'})\n",
    "df_trips['Starttime'] = pd.to_datetime(df_trips['Starttime'])\n",
    "df_trips['Stoptime'] = pd.to_datetime(df_trips['Stoptime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-sauce",
   "metadata": {},
   "source": [
    "Now, we will repeat the same process for the station locations as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "healthy-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('healthy-ride-station-locations-2021-q1.csv', dtype=\"str\", keep_default_na=False)\n",
    "# Dropping columns that are not as useful\n",
    "df = df.drop(['# of Racks'], axis=1)\n",
    "df = df.astype({'Latitude': 'float64', 'Longitude' : 'float64'})\n",
    "# Fixing an error in the input data (it used the wrong sign for latitude data)\n",
    "df.loc[86, 'Latitude'] = 40.467715"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-bullet",
   "metadata": {},
   "source": [
    "TODOS:\n",
    "- Add labels, colors to the nodes, increase canvas size\n",
    "- (DONE) Represent cycling data as graph with proper relative positions\n",
    "- (DONE) Sizes based on number of trips to a given node\n",
    "- (DONE) Sizes based on number of trips starting at a given node\n",
    "- (DONE) Find average time for each start, end dest.\n",
    "- Find avg trip time on weekends vs weekdays\n",
    "- Find avg trip time on mornings vs evenings\n",
    "- (DONE) Visualize most popular trips\n",
    "- Find additional data to analyze via network and gmaps/pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-central",
   "metadata": {},
   "source": [
    "# Initial insights into trip patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-pierce",
   "metadata": {},
   "source": [
    "Now, we set up all our data from the 2 csv files - for trips and station information. Immediately, from looking at the aggregated data, we can see that most trips are trips that end at the origin (random biking trips that start and begin at the same place). This is true for a majority of stations, as can be seen from the analysis below in which we group data based on the origin and dest, count the number of trips, and rank them in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "systematic-tobacco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     From station id                         From station name To station id  \\\n",
      "294             1012  North Shore Trail & Fort Duquesne Bridge          1012   \n",
      "1459            1061                       33rd St & Penn Ave           1061   \n",
      "0               1000                  Liberty Ave & Stanwix St          1000   \n",
      "1662            1084                Hot Metal St & Tunnel Blvd          1084   \n",
      "1189            1045  S 27th St & Sidney St. (Southside Works)          1045   \n",
      "1637            1074               South Side Trail & S 4th St          1074   \n",
      "1736            1093                S Bouquet Ave & Sennott St          1093   \n",
      "1975           49301                   Centre Ave & N Craig St         49301   \n",
      "1263            1048                     S 18th St & Sidney St          1048   \n",
      "2198           49671                         9th St & Penn Ave          1017   \n",
      "\n",
      "                               To station name  count  \n",
      "294   North Shore Trail & Fort Duquesne Bridge    372  \n",
      "1459                       33rd St & Penn Ave     337  \n",
      "0                     Liberty Ave & Stanwix St    262  \n",
      "1662                Hot Metal St & Tunnel Blvd    183  \n",
      "1189  S 27th St & Sidney St. (Southside Works)    178  \n",
      "1637               South Side Trail & S 4th St    127  \n",
      "1736                S Bouquet Ave & Sennott St    114  \n",
      "1975                   Centre Ave & N Craig St    109  \n",
      "1263                     S 18th St & Sidney St    108  \n",
      "2198                        21st St & Penn Ave     96  \n"
     ]
    }
   ],
   "source": [
    "df_grouped = df_trips.groupby(['From station id','From station name', 'To station id','To station name']).size().reset_index(name=\"count\").sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-diversity",
   "metadata": {},
   "source": [
    "We can see that the North Shore Trail & Fort Duquesne Bridge is the most popular station."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-track",
   "metadata": {},
   "source": [
    "As you can see, when we aggregate data to see which trips are the most popular, 9 out of 10 of the top 10 trips begin and end at the same station."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-confirmation",
   "metadata": {},
   "source": [
    "We will be visualizing this data later on in the form of a Google map.  \n",
    "Now, we will also be attempting to look at trips that start and end at distinct stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "southern-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_different_start_end = df_trips[df_trips['From station id'] != df_trips['To station id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-romania",
   "metadata": {},
   "source": [
    "Now, let's look at the same aggregation (most popular trips), but for trips that end at different locations. This can help us understand data fpor trips that are likely for a purpose (people take trips to different stations to run errands, get to work etc.) compared to trips that end up at the same station which are more likely to be for leisure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "gothic-contribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     From station id                  From station name To station id  \\\n",
      "2108           49671                  9th St & Penn Ave          1017   \n",
      "1356            1059  Burns White Center at 3 Crossings          1060   \n",
      "608             1024           S Negley Ave & Baum Blvd          1028   \n",
      "1381            1060                 Penn Ave & 29th St          1059   \n",
      "432             1017                 21st St & Penn Ave         49671   \n",
      "1714            1094              O'Hara St & Desoto St         49301   \n",
      "625             1024           S Negley Ave & Baum Blvd         49401   \n",
      "1936           49401         Stanton Ave & N Negley Ave          1024   \n",
      "1612            1088             Frazier St & Dawson St          1093   \n",
      "1711            1094              O'Hara St & Desoto St          1097   \n",
      "\n",
      "                           To station name  count  \n",
      "2108                    21st St & Penn Ave     96  \n",
      "1356                    Penn Ave & 29th St     66  \n",
      "608   Penn Ave & Putnam St (Bakery Square)     65  \n",
      "1381     Burns White Center at 3 Crossings     62  \n",
      "432                      9th St & Penn Ave     57  \n",
      "1714               Centre Ave & N Craig St     54  \n",
      "625             Stanton Ave & N Negley Ave     49  \n",
      "1936              S Negley Ave & Baum Blvd     48  \n",
      "1612            S Bouquet Ave & Sennott St     42  \n",
      "1711              Tennyson Ave & Fifth Ave     41  \n"
     ]
    }
   ],
   "source": [
    "df_trips_different_start_end = df_trips_different_start_end.groupby(['From station id','From station name', 'To station id','To station name']).size().reset_index(name=\"count\").sort_values(\"count\", ascending=False)\n",
    "\n",
    "print(df_trips_different_start_end.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-pillow",
   "metadata": {},
   "source": [
    "We can see the most popular trip is from 9th St & Penn Ave to 21st St & Penn Ave. We will visualize these trips later using Google maps as well to see how these trips look geographically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-ukraine",
   "metadata": {},
   "source": [
    "# Setting up a Network Graph\n",
    "Before we visualize the trip information, it is useful to store the trips as a network graph so that we extract useful analyses from it. For example, once we add all the stations as nodes, we can store their positions as attributes and the edges can correspond to trips. This will allow us to take advantage of networkx's functionality to extract the degree and other network properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bronze-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the graph using networkx\n",
    "X = nx.Graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-domain",
   "metadata": {},
   "source": [
    "We need to extract the positions data, as well as a list of all the station names.  \n",
    "By setting up a set of nodes, we can ensure that the trips correspond to stations for which we have positional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "surprised-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "posList = list(zip(df['Latitude'], df['Longitude']))\n",
    "labels_list = list(df['Station Name'])\n",
    "setOfNodes = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-anniversary",
   "metadata": {},
   "source": [
    "Now, we can add each station as a node to the graph, as well as edges for each distinct trip. To do this, we will go through each row of the stations dataframe and add these as nodes to the graph. After this, we will go through the trips dataframe and add an edge for each trip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "optimum-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating through the stations\n",
    "for (i, row) in df.iterrows():\n",
    "    setOfNodes.add(row[0])\n",
    "    X.add_node(row[0], pos=posList[i])\n",
    "\n",
    "# Iterating through the trips\n",
    "for (i, row) in df_trips.iterrows():\n",
    "    if row[4] in setOfNodes and row[5] in setOfNodes:\n",
    "        X.add_edge(row[4], row[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-cowboy",
   "metadata": {},
   "source": [
    "Now, we will get the degree of the graph.\n",
    "The degree of a node is the number of edges the end at the node. This number will tell us the number of trips that start/end at a given station. If we wish to compare stations based on this, we can store the degrees in a list and use it later when we visualize the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "thousand-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = X.degree\n",
    "weights = []\n",
    "for (k, v) in degrees:\n",
    "    weights.append(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-disclosure",
   "metadata": {},
   "source": [
    "# Using Google Maps to visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-result",
   "metadata": {},
   "source": [
    "We will be using the gmaps library to display our location data in a form that can be visualized and understood. Let us try some basic functions of this library through some sample code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "pittsburgh = (40.4406, -79.9959)\n",
    "fig = gmaps.figure(center=pittsburgh, zoom_level=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-queen",
   "metadata": {},
   "source": [
    "Finally, before we visualize our data in the form of a map, we need to get the positional data in a format that can be consumed by the gmaps library (for example, a dictionary). We will use the networkx function to get the position attribute of each node a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "brown-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "posDict = nx.get_node_attributes(X,'pos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-intervention",
   "metadata": {},
   "source": [
    "Plot these coordinates on a Google map to show the points on a map\n",
    "Show the connections if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-leonard",
   "metadata": {},
   "source": [
    "Drawing the map of Pittsburgh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "about-campbell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "naughty-checklist",
   "metadata": {},
   "source": [
    "Drawing a heatmap showing the concentration of cycle stations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "abandoned-qualification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c526e80b2e3942fcb058ae31973765ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap_layer = gmaps.heatmap_layer(posList, weights=weights)\n",
    "heatmap_layer.point_radius = 20\n",
    "fig.add_layer(heatmap_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "pharmaceutical-cuisine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c526e80b2e3942fcb058ae31973765ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig.add_layer(gmaps.bicycling_layer())\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-meter",
   "metadata": {},
   "source": [
    "Drawing markers showing each cycle station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fitting-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18322a81ac90486fbf47191df3107e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = gmaps.figure()\n",
    "markers = gmaps.marker_layer(posList)\n",
    "for i in range(len(markers.markers)):\n",
    "    #     Adding hover text for the markers\n",
    "    markers.markers[i].info_box_content = labels_list[i]\n",
    "    markers.markers[i].display_info_box = True\n",
    "fig.add_layer(markers)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "close-skill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986e3d26b3d940dca762fd9f38465b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Figure(layout=FigureLayout(height='420px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = []\n",
    "\n",
    "data = df_grouped.head(20)\n",
    "\n",
    "# For top 20 trips\n",
    "def calculate_trips1(df_trips):\n",
    "    for (i, row) in df_trips.iterrows():\n",
    "        if row[0] in setOfNodes and row[1] in setOfNodes:\n",
    "            features.append(gmaps.Line(\n",
    "                start=posDict[row[0]],\n",
    "                end=posDict[row[1]],\n",
    "                stroke_weight=3.0,\n",
    "                stroke_color=\"black\"\n",
    "            ))\n",
    "            \n",
    "setOfPoints = set()\n",
    "\n",
    "for (i, row) in data.iterrows():\n",
    "    setOfPoints.add(row[0])\n",
    "    setOfPoints.add(row[1])\n",
    "\n",
    "colors = []\n",
    "for pos in posDict:\n",
    "    if pos in setOfPoints:\n",
    "        colors.append('blue')\n",
    "    else:\n",
    "        colors.append('red')\n",
    "\n",
    "        \n",
    "symbol_layer = gmaps.symbol_layer(posList, info_box_content=labels_list, fill_color=colors, scale=3)\n",
    "\n",
    "calculate_trips1(data)\n",
    "drawing = gmaps.drawing_layer(features=features)\n",
    "markers = gmaps.marker_layer(posList)\n",
    "fig.add_layer(symbol_layer)\n",
    "fig.add_layer(drawing)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-serum",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "simplified-maximum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  From station id To station id Tripduration                     \n",
      "                                         min    max          mean\n",
      "0            1000          1001          200  70805   9878.060606\n",
      "1            1000          1002          206   3296   2201.750000\n",
      "2            1000          1003        57710  57710  57710.000000\n",
      "3            1000          1006          351    463    413.750000\n",
      "4            1000          1007          751   1742   1248.090909\n",
      "5            1000          1008          574    731    640.200000\n",
      "6            1000          1010         1476   4130   3241.000000\n",
      "7            1000          1011         8021  69580  38800.500000\n",
      "8            1000          1012          570  53944   4786.217391\n",
      "9            1000          1013          693  56621   9252.000000\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df_trips.groupby(['From station id', 'To station id']).agg({\"Tripduration\" : [\"min\", \"max\", \"mean\"]}).reset_index()\n",
    "print(df_grouped.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-jordan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekends = df_trips[df_trips['Starttime'].dt.dayofweek > 5]\n",
    "df_grouped = df_weekends.groupby(['From station id', 'To station id']).agg({\"Tripduration\" : [\"min\", \"max\", \"mean\"]}).reset_index()\n",
    "print(df_grouped.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mornings = df_trips[df_trips['Starttime'].dt.hour < 12]\n",
    "df_grouped = df_mornings.groupby(['From station id', 'To station id']).agg({\"Tripduration\" : [\"min\", \"max\", \"mean\"]})\n",
    "print(df_grouped.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mornings = df_trips[df_trips['Starttime'].dt.hour < 12]\n",
    "df_grouped = df_mornings.groupby(['From station id', 'To station id']).agg({\"Tripduration\" : [\"min\", \"max\", \"mean\"]})\n",
    "df_grouped = df_grouped[]\n",
    "print(df_grouped.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evenings = df_trips[df_trips['Starttime'].dt.hour > 16]\n",
    "df_grouped = df_evenings.groupby(['From station id', 'To station id']).agg({\"Tripduration\" : [\"min\", \"max\", \"mean\"]}).reset_index()\n",
    "print(df_grouped.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
